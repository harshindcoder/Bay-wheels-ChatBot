{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1 - ðŸ§  Retrieval-Augmented Generation (RAG) Prototype for Bay Wheels (Lyft)\n",
        "In this notebook, we implemented a Retrieval-Augmented Generation (RAG) pipeline for Bay Wheels, a bike-sharing service operated by Lyft. The goal was to build a chatbot capable of answering typical business and sales-related queries such as:\n",
        "\n",
        "â€œWhich area has the highest number of trips in a day?â€\n",
        "\n",
        "â€œWhat are the pricing plans or ticket options?â€\n",
        "\n",
        "â€œHow many stations are available across the network?â€\n",
        "\n",
        "While this is a prototype, the full trips dataset has not yet been embedded into the vector database. However, the chatbot can still respond to general questions about Bay Wheels based on the available data.\n",
        "\n",
        "We used Pinecone as the Vector Database (VectorDB) for efficient document retrieval and Mistral, a lightweight, open-source language model running locally via the Ollama framework.\n",
        "This switch to a local model was necessary due to OpenAI API quota limitations during testing."
      ],
      "metadata": {
        "id": "uGc4pil6EwHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fallback to Local LLM (Ollama)\n",
        "\n",
        "Initially, this notebook used the OpenAI GPT-4 model via the `ChatOpenAI` API for answering questions using a Retrieval-Augmented Generation (RAG) pipeline.\n",
        "\n",
        "However, due to **OpenAI API quota limitations** (error code `429 - insufficient_quota`), the pipeline now uses a **local open-source LLM** (`mistral`) through the [Ollama](https://ollama.com) framework.\n"
      ],
      "metadata": {
        "id": "QPv_jo0nEeO5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Packages"
      ],
      "metadata": {
        "id": "2Zymn_mXDgO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.llms import Ollama\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "zE9sw0SVAr1o"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Pinecone Index"
      ],
      "metadata": {
        "id": "W-i6fSf3DmqT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "en8ZYr0GAJw_",
        "outputId": "e8f3fdba-a0fb-4270-c0f5-c47eb08e493e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Set your API keys for Pinecone\n",
        "pc = Pinecone(\n",
        "    api_key=os.environ['PINECONE_API_KEY']\n",
        ")\n",
        "\n",
        "# Create Index if not already created\n",
        "pinecone_index_name = \"langchain-embeddings-demo\"\n",
        "if pinecone_index_name not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name=pinecone_index_name,\n",
        "        dimension=384, # '384' is the dimension for ada-002 embeddings\n",
        "        metric='cosine',\n",
        "        spec=ServerlessSpec(\n",
        "            cloud='aws',\n",
        "            region='us-east-1'\n",
        "        )\n",
        "    )\n",
        "\n",
        "    while not pc.describe_index(pinecone_index_name).index.status['ready']:\n",
        "        time.sleep(1)\n",
        "\n",
        "    print(\"Pinecone Index provisioned\")\n",
        "else:\n",
        "    print(\"Pinecone Index Already Provisioned\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating And Loading Embeddings"
      ],
      "metadata": {
        "id": "BzINqZqKDxCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Initialize HuggingFace Embeddings (no API key required)\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")  # You can choose other models too\n",
        "\n",
        "# 2. Load all text files from a directory\n",
        "directory_path = \"Desktop/Lyft-Project/Lyft-baywheels-ChatBot/data\"  # Path to your folder with .txt files\n",
        "loader = DirectoryLoader(directory_path, glob=\"*.txt\", loader_cls=TextLoader)\n",
        "documents = loader.load()\n",
        "\n",
        "# 3. Split documents into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=50)\n",
        "split_documents = text_splitter.split_documents(documents)\n",
        "\n",
        "# 4. Connect to Pinecone and insert documents\n",
        "pinecone_index_name = \"langchain-embeddings-demo\"\n",
        "\n",
        "vectorstore = PineconeVectorStore(index_name=pinecone_index_name, embedding=embeddings)\n",
        "vectorstore.add_documents(documents=split_documents)\n",
        "\n",
        "print(\"âœ… Embeddings from local HuggingFace model created and stored in Pinecone Vector Database!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m22GVD7hAWzF",
        "outputId": "430de65e-d4ad-41a9-bd60-a34c782f4688"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Embeddings from local HuggingFace model created and stored in Pinecone Vector Database!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Asking the Questions and Getting Answers"
      ],
      "metadata": {
        "id": "BWq-Om5XD6dO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load Embeddings (from HuggingFace)\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# 2. Connect to Pinecone (already created)\n",
        "pinecone_index_name = \"langchain-embeddings-demo\"\n",
        "vector_store = PineconeVectorStore(index_name=pinecone_index_name, embedding=embeddings)\n",
        "\n",
        "# 3. Define Retriever\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 1})\n",
        "\n",
        "# 4. Use Ollama's local model as the LLM (like mistral, llama3, gemma)\n",
        "llm = Ollama(model=\"mistral\")  # You can also use \"llama3\", \"gemma\", etc.\n",
        "\n",
        "# 5. Define Prompt Template\n",
        "prompt_template = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "Use the following context to answer the question as accurately as possible.\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer:\"\"\",\n",
        "    input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "# 6. Create the LLM Chain\n",
        "llm_chain = prompt_template | llm | StrOutputParser()\n",
        "\n",
        "# 7. Ask a Question\n",
        "query = \"What are the number of stations for baywheels?\"\n",
        "docs = retriever.invoke(query)\n",
        "context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "\n",
        "# 8. Run the RAG pipeline\n",
        "answer = llm_chain.invoke({\"context\": context, \"question\": query})\n",
        "\n",
        "# 9. Output the Answer\n",
        "print(\"Question:\", query)\n",
        "print(\"Answer:\", answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZCl_F3fAdS3",
        "outputId": "78b49698-4e57-4bf4-f682-ba59727e092f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the number of stations for baywheels?\n",
            "Answer:  As of January 2018, there were 262+ docking stations for Bay Wheels (Lyft Bikes). However, keep in mind that this number might have changed since then.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deleting Pinecone Index"
      ],
      "metadata": {
        "id": "n_AZT7SzK7xp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your API keys for Pinecone\n",
        "pc = Pinecone(\n",
        "    api_key=os.environ['PINECONE_API_KEY']\n",
        ")\n",
        "\n",
        "# Create Index if not already created\n",
        "pinecone_index_name = \"langchain-embeddings-demo\"\n",
        "if pinecone_index_name in pc.list_indexes().names():\n",
        "    pc.delete_index( name=pinecone_index_name )\n",
        "\n",
        "    print(\"Pinecone Index Deleted\")\n",
        "else:\n",
        "    print(\"Pinecone Index Had Already been Deleted\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25QkTR6jAi73",
        "outputId": "4b34dc07-0f3d-43bc-90d9-fcf7bf7fb04f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pinecone Index Deleted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# File Embedded in the Vector Database\n",
        "\n",
        "This file contains a structured text summary of Bay Wheels (Lyft) data, scraped from the official Lyft website and Wikipedia. It was embedded into the VectorDB for retrieval and chatbot testing.\n",
        "\n",
        "---\n",
        "\n",
        "## **Bay Wheels (Lyft Bikes) â€“ System Overview & Data Summary**\n",
        "\n",
        "### 1. Operating Entity\n",
        "- Operated by **Motivate**, owned by **Lyft**.  \n",
        "  *Reference: [1]*\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Service Area & Fleet\n",
        "- Operates in: **San Francisco Bay Area** (San Francisco, East Bay, San Jose)  \n",
        "- Fleet: ~2,600+ bicycles, 262+ docking stations *(as of Jan 2018)*  \n",
        "  *Reference: [2]*\n",
        "\n",
        "---\n",
        "\n",
        "### 3. History & Launch Dates\n",
        "- **Aug 29, 2013** â€“ Launched as *Bay Area Bike Share*  \n",
        "- **June 28, 2017** â€“ Rebranded to *Ford GoBike*  \n",
        "- **June 11, 2019** â€“ Relaunched as *Bay Wheels* under Lyft  \n",
        "  *References: [3], [4], [5]*\n",
        "\n",
        "---\n",
        "\n",
        "### 4. System Expansion Goals\n",
        "- Planned growth to:  \n",
        "  â†’ ~7,000 bikes  \n",
        "  â†’ ~540 stations (across SF, Oakland, Berkeley, Emeryville, San Jose)  \n",
        "  *Reference: [6]*\n",
        "\n",
        "---\n",
        "\n",
        "### 5. Bike Types & Technology\n",
        "- Classic **docked bikes** and hybrid **eâ€‘bikes**  \n",
        "- Dockless option with built-in lock  \n",
        "- **Clipper card** supported for contactless access  \n",
        "- Bikes by **8D Technologies** and **Motivate**  \n",
        "  *Reference: [7]*\n",
        "\n",
        "---\n",
        "\n",
        "### 6. Pricing (Effective mid 2025)\n",
        "- Single Ride: 3.99 dollar / 30 min\n",
        "- Day Pass: 15 dollar/day (unlimited 30-min classic rides)  \n",
        "- Monthly: 29 dollar/month (45 min free + ebike discounts)  \n",
        "- Annual: 150 dollar/year  \n",
        "- Lyft Pink: 199 dollar/year (includes rideshare perks)  \n",
        "  *Reference: [8]*\n",
        "\n",
        "---\n",
        "\n",
        "### 7. How It Works\n",
        "1. Unlock via Lyft app or Clipper QR  \n",
        "2. Ride  \n",
        "3. Return to dock for free (or $2 lock fee for eâ€‘bike racks)  \n",
        "  *Reference: [9]*\n",
        "\n",
        "---\n",
        "\n",
        "### 8. Additional Features\n",
        "- **Ride Together**: unlocks bikes for guests  \n",
        "- **Bike Angels**: rebalancing incentive program  \n",
        "  *References: [10], [11]*\n",
        "\n",
        "---\n",
        "\n",
        "### 9. Data & Developer Access\n",
        "- Open access to trip histories, ridership, membership stats  \n",
        "  *Reference: [12]*\n",
        "\n",
        "---\n",
        "\n",
        "### 10. Resources & Extras\n",
        "- Blog updates, adaptive bikeshare logs, art bike initiatives  \n",
        "  *Reference: [13]*\n",
        "\n",
        "---\n",
        "\n",
        "> This file was generated using ChatGPT to scrape and summarize content from official Bay Wheels sources.\n"
      ],
      "metadata": {
        "id": "RObjG_ZYGH6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Future Enhancement: Integrating Trip-Level Data in Production\n",
        "While this prototype focuses on answering general business and operational questions using curated Bay Wheels data, the model's usefulness can be significantly enhanced in a production setting by incorporating detailed trip-level datasets.\n",
        "\n",
        "The raw trip data includes fields such as duration_sec, start_time, end_time, start_station_name, end_station_id, and user_type, which can provide rich insights into rider behavior, traffic patterns, and operational bottlenecks.\n",
        "\n",
        "However, due to the large size and granularity of this dataset, it has been excluded from this prototype to maintain performance and minimize vector database load.\n",
        "\n",
        "In a real-world deployment, this trip data can be transformed before embedding by:\n",
        "\n",
        "Aggregating the number of trips between stations per day\n",
        "\n",
        "Summarizing peak usage periods by station\n",
        "\n",
        "Creating department-specific views (e.g., operations vs. planning)\n",
        "\n",
        "This structured summarization approach would retain critical insights while keeping the RAG system optimized and scalable for production."
      ],
      "metadata": {
        "id": "qW5Joph3OPli"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FizXr158NY2t"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}